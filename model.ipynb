{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcm_library import *\n",
    "from acquire import *\n",
    "from prepare import *\n",
    "# Sklearn stuff:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you create several variable arrays each representing hyperparameter eg $h_1$ ,...,$h_n$ . Then you iterate through each $h_i$  and apply the cartesian product you will have a list with every potential hyperparameter combination.\n",
    "\n",
    "\n",
    "Since it is computationaly expensive maybe keep each range under 3 unless something looks really interesting. \n",
    "\n",
    "As the overall length of tuples generated will be \n",
    "len( $h_1$ ) $\\times$ len( $ h_2$ ) ,..., $\\times$ len( $ h_n $ ) \n",
    "\n",
    "e.g. if len($h_1$)=len($h_2$)=len($h_3$)=5 then  $5^3$ already becomes 125 operations\n",
    "\n",
    "\n",
    "When we are considering combinations, always try to minimize them by creating entry points that restrict things\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Decision Tree\n",
    "\n",
    "\n",
    ">1. Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    ">\n",
    ">1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    ">\n",
    ">1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    ">\n",
    ">1. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    ">\n",
    ">1. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    ">\n",
    ">1. Run through steps 2-4 using a different max_depth value.\n",
    ">\n",
    ">1. Which model performs better on your in-sample data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. Which model performs best on your out-of-sample data, the validate set?\n",
    ">\n",
    ">1. Work through these same exercises using the Telco dataset.\n",
    "Experiment with this model on other datasets with a higher number of output classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Random Forest\n",
    "\n",
    "Continue working in your model file with titanic data to do the following:\n",
    ">\n",
    ">1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    ">\n",
    ">1. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    ">\n",
    ">1. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    ">\n",
    ">1. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    ">\n",
    ">1. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    ">\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: KNN\n",
    "\n",
    "Continue working in your model file with the titanic dataset.\n",
    " \n",
    ">1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "> \n",
    ">1. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "> \n",
    ">1. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    ">\n",
    ">1. Run through steps 2-4 setting k to 10\n",
    "> \n",
    ">1. Run through setps 2-4 setting k to 20\n",
    "> \n",
    ">1. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "> \n",
    ">1. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw:</th>\n",
       "      <td>891</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prep:</th>\n",
       "      <td>891</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length  Width\n",
       "Raw:      891     14\n",
       "Prep:     891     13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>deck</th>\n",
       "      <th>survived_1</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>alone_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unique Counts:</th>\n",
       "      <td>891</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                passenger_id  age  sibsp  parch  fare  deck  survived_1  \\\n",
       "Unique Counts:           891   88      7      7   248     7           2   \n",
       "\n",
       "                sex_male  class_Second  class_Third  embark_town_Queenstown  \\\n",
       "Unique Counts:         2             2            2                       2   \n",
       "\n",
       "                embark_town_Southampton  alone_1  \n",
       "Unique Counts:                        2        2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   age                      891 non-null    float64\n",
      " 1   sibsp                    891 non-null    int64  \n",
      " 2   parch                    891 non-null    int64  \n",
      " 3   fare                     891 non-null    float64\n",
      " 4   survived_1               891 non-null    uint8  \n",
      " 5   sex_male                 891 non-null    uint8  \n",
      " 6   class_Second             891 non-null    uint8  \n",
      " 7   class_Third              891 non-null    uint8  \n",
      " 8   embark_town_Queenstown   891 non-null    uint8  \n",
      " 9   embark_town_Southampton  891 non-null    uint8  \n",
      " 10  alone_1                  891 non-null    uint8  \n",
      "dtypes: float64(2), int64(2), uint8(7)\n",
      "memory usage: 40.9 KB\n"
     ]
    }
   ],
   "source": [
    "titanic=get_titanic_data()\n",
    "titanic=prep_titanic(titanic)\n",
    "titanic.drop(columns=[\"passenger_id\",'deck'], inplace=True)\n",
    "titanic.age=titanic.age.astype(str).replace('nan',f'{titanic.age.mean():.1f}').astype(float)\n",
    "titanic.info()\n",
    "\n",
    "# titanic.age.mode()\n",
    "# titanic.age.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# titanic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prepared Data</th>\n",
       "      <td>891</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>534</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validate</th>\n",
       "      <td>178</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>179</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Length  Width\n",
       "Prepared Data     891     11\n",
       "Train             534     11\n",
       "Validate          178     11\n",
       "Test              179     11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_titanic,validate_titanic,test_titanic =split_data(titanic,tostratify='survived_1')\n",
    "titanicDflist=[train_titanic,validate_titanic,test_titanic]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAAAUCAYAAADx7wHUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABJ0AAASdAHeZh94AAAEm0lEQVR4nO3YZ4hdVRAH8F+ioLKiQsQExd5RsWI3GksULFgQv9giiqIYFIMNdDKKGrE3bJFEo6BCLNhRDMbeJYoNS9QPSewlIbHE9cO5T17e3vd2X1xXEf9wGe7cmXPmzJ05M+cM6+3t9T8GB8P/aQP+S1i2jpmZd2A/rBsRC4bWpH8/MnNbvIbjI+K2Bn9Ya5pn5nZ4BRMi4som/mys3Wb8eRExqmbSS7EdNsKqWIjP8ACuj4hvBmD4Ubijej0hIib3p9MNMnMEDsH+2AJr4Be8jSmYEhG/1+jdjx2xYUTMpz7NL8aPuLHm2w/ImufyNraejh48iWtwF37DRMzKzDX7WeiauA7zO8n9RRyOW7EDXsbVmI7NMRn3ZuawGr1LMArjG4wl0jwzN8LemBwRC2sG+D4iJnZh6EoRsaiVmZkX4Vycg5PrFKsFTME3uA8Tupi3G3yIg/BIcwRm5rlKhh6GQxUH/4mIeCUz38eJmXlpRCxujczjMAz3DIaVdY6scG9FN+ygPh57Yhz+tn07Ip6OiIdaUzki5uKm6nWPNup3Yy0lAPsUoL2xGC+1UV4uM4+sBliAWZgZEYu7XMOBFZ1V9zEzN8UkXBMRMzNzzy7HHyz8WtHf2nx/vqL74Ik/nZmZPdgK73Wo4KMwrYX3aWaOi4hn2lmUmROwIlZWCtKuiiMn1cguW83xubIV/COo7Di6en28jdirFR3NkgVoDSyDOW0Up2AvxaE9SuW7GevgsczcsoNtExA4TXHk4xgbEV/VyJ6PrXFsm317qDBJKUKPRsQTdQIR8QMWKZm6RJqPqOh3bRSzhfUOTsrM+ThDqdCHtNEdBZk5EjtXhr6ZmQdExBsNuczcXonGKyLixbbL/JuRmeOVNb2Po/oR/xYjWTIyG1GwfJdzNzbp0f0JRsS8iLgfY5Wf1+gfm9P7Q5zXpQ2Dhsw8RWnj3sWYiPi2H5UVVL5rduaXFR3RR7wzGno9A1WIiM8UYzfLzFUr9opKc78pFmVmb+NRtgi4teJd3aWNA0JmnobrlawbU1X0TvLDsYrKB81pPgdfYeMubdipop90qbd6RRudwM+4rY3sNso++hw+wKBvAZl5lrL9vIV9IuLrAahtrLSSb9HkzIjozcyZOCwzN4iIj5om2gxzWkM+M9dW/iTc2fJtE6XJn9vCH44LsRpeiIjvqvkX4vg2C52oOPP21uNkZk7FMRgXEVP7XX79+OfhAryuFMb+UruBHSs6g7595nSl498XHzXxD8fZmTkDn+InrK+cZ5fHo/oeKffDZdUP+lg5yYzE7lgPc3HCAI3uhMZW1a4X7IjMPEZx5GI8i/GZrbXW7DY/amyl9yD1zpyn9Fc3NPFnKCG9tZLWPfheSbtpmBYRrRejT+EW7IItlb1lgVJgpuHaLiKgE7ZQfu4jS6m/bkWXUVq3OjyDqc2MzFwZB+PhiPiC+lujc5TLjm0i4s2lNHBIkJmrKBF/RUScOcRzn4prMToinqX+1ugq5fRxwRDatrTYTTnyXdmf4GAiM1dQLmmmNxxJTWRWwqMxBpf/fzncF9XdwRGYGhGzG/w/AE8qpS9QclOhAAAAAElFTkSuQmCC",
      "text/latex": [
       "\\begin{equation*}\\left( 534, \\  2\\right)\\end{equation*}"
      ],
      "text/plain": [
       "(534, 2)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_knn_variables=[(i.drop(columns=['survived_1']),i.survived_1) for i in titanicDflist]\n",
    "## This is for train\n",
    "X_train=titanic_knn_variables[0][0]## the X var for train\n",
    "y_train=titanic_knn_variables[0][1]# the y var for train\n",
    "# display(X_train,y_train)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "# display(knn.classes_)##best way to see order of knn.predict\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba.shape\n",
    "# pd.crosstab(y_train, y_pred)\n",
    "# print(classification_report(y_train, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate=titanic_knn_variables[1][0]## the X var for val\n",
    "y_validate=titanic_knn_variables[1][1]# the y var for validate\n",
    "# display(X_train,y_train)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_validate, y_validate)\n",
    "y_pred = knn.predict(X_validate)\n",
    "# display(knn.classes_)##best way to see order of knn.predict\n",
    "y_pred_proba = knn.predict_proba(X_validate)\n",
    "# y_pred_proba.shape\n",
    "# pd.crosstab(y_validate, y_pred)\n",
    "# print(classification_report(y_validate, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_neighbors</th>\n",
       "      <th>2_neighbors</th>\n",
       "      <th>3_neighbors</th>\n",
       "      <th>4_neighbors</th>\n",
       "      <th>5_neighbors</th>\n",
       "      <th>6_neighbors</th>\n",
       "      <th>7_neighbors</th>\n",
       "      <th>8_neighbors</th>\n",
       "      <th>9_neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validate_score</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1_neighbors  2_neighbors  3_neighbors  4_neighbors  \\\n",
       "train_score            0.99         0.84         0.85         0.80   \n",
       "validate_score         0.70         0.66         0.72         0.71   \n",
       "diff                   0.29         0.17         0.12         0.09   \n",
       "\n",
       "                5_neighbors  6_neighbors  7_neighbors  8_neighbors  \\\n",
       "train_score            0.79         0.78         0.78         0.77   \n",
       "validate_score         0.70         0.71         0.70         0.71   \n",
       "diff                   0.09         0.07         0.08         0.06   \n",
       "\n",
       "                9_neighbors  \n",
       "train_score            0.76  \n",
       "validate_score         0.67  \n",
       "diff                   0.09  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration:\n",
    "model_set = []\n",
    "model_accuracies = {}\n",
    "X_train=titanic_knn_variables[0][0]## the X var for train\n",
    "y_train=titanic_knn_variables[0][1]# the y var for train\n",
    "X_validate=titanic_knn_variables[1][0]## the X var for val\n",
    "y_validate=titanic_knn_variables[1][1]\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_set.append(clf)\n",
    "    model_accuracies[f'{i}_neighbors'] = {\n",
    "        'train_score': round(clf.score(X_train, y_train), 2),\n",
    "        'validate_score': round(clf.score(X_validate, y_validate), 2),\n",
    "        'diff': round(abs(clf.score(X_train, y_train)-clf.score(X_validate, y_validate)),2)}\n",
    "\n",
    "pd.DataFrame(model_accuracies)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACYAAAAQCAYAAAB6Hg0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABJ0AAASdAHeZh94AAACb0lEQVR4nM3VTahVVRQH8N/VCkRMTXg5SDKf2uSFDvx84UdhGjixeE4iiGZCoYUOxcVKHPpBQeMQHEgNiihUiuCFKQ8MJCJS38NBIZn2FAsbRNfB2VeOh3ut5x3UgsOfs9f6r/Pfa++1Tqvdbvs/2kP1l8wcwQYsxzLMwrGIePV+STJzHd7CMB7Db/gORyLi8y7xT+AdvIh5uIKPkRExCdManL14swj7+d/sLDP3YhTrcQIH8SnmYmOX+EGcw+sYw2FMYBfOZOY8GhXD2/gJl1SV++ofRG3HfnyBlyPiVsP/cBfa+xjAzoh4rxZ7qHz/AHa0et2xzNxYhHU9ysycVjbwOBZGxK/320ThLMI4LmMwIv6u+WapjrSFgWbFpmLDeAofYTIzt2IIf2IsIs504Txf8FRdFETErcw8jc1Y04+wlQV/wbd4pu7MzFGMNCr5dMELPXJeLMKWNi//VGyg4A7MwCZVFw/hpKoZPmxwZhe82SNnZ31OP8KmF2ypKvNlRPweEd/jJVUTbcjMtVPI2SrY7kfYZMGJiDhfd0TEbVXVYFXN1anIbN3t0U5cP8J+LHijh78jfEYXztIenCUFL/QjbBR/YUlmPtLFP1Twcm2tMxc3l3Fz18q4eBa3cfaBhUXENRxXHcu+xkdewBbV0Z2occZxCgvxRiNlYiaORsQf9wzYzNyGbeV1fkk+ga/L2rWI2FOLH8BpLC4xY3hSdfnbeCUi7unM8kv6RtXVn+AHrMZzqjEyHBHXmxVbjtfKs6WsLaqtjdSDI+JqSXoYC7BTNUQ/w7qmqMIZxwp8ULi7MYh3sTYirkPPX9J/bXcAnxjLKMKBHBQAAAAASUVORK5CYII=",
      "text/latex": [
       "\\begin{equation*}160\\end{equation*}"
      ],
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def knn_hyperpars_tupples( n_neighbors_arr=range(10,21,10),\n",
    "    weights_arr=['uniform', 'distance'],\n",
    "    leaf_size_arr=range(30,50,2),\n",
    "    p_arr=[1,2,3,4]):\n",
    "    '''\n",
    "    explore first to get decent ranges, this step is expensive\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    n_jobs : int, default=None\n",
    "    The number of parallel jobs to run for neighbors search.\n",
    "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "    for more details.\n",
    "    Doesn't affect :meth:`fit` method.\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "   \n",
    "   \n",
    "    knn_tupple_array=[n_neighbors_arr,weights_arr,leaf_size_arr,p_arr]\n",
    "\n",
    "    tupples=list(reduce(product,knn_tupple_array))\n",
    "\n",
    "    tupples=[[tupples[i][0][0][0],tupples[i][0][0][1],tupples[i][0][1],tupples[i][1]]for i in range(0,len(tupples))]\n",
    "  \n",
    "    \n",
    "\n",
    "    return tupples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "knn_tupples=knn_hyperpars_tupples()\n",
    "\n",
    "len(knn_tupples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "\n",
    "# iteration:\n",
    "dfdict={}\n",
    "for i,t in enumerate(knn_tupples):\n",
    "    \n",
    "    model_set = []\n",
    "    model_accuracies = {}\n",
    "    X_train=titanic_knn_variables[0][0]## the X var for train\n",
    "    y_train=titanic_knn_variables[0][1]# the y var for train\n",
    "    X_validate=titanic_knn_variables[1][0]## the X var for val\n",
    "    y_validate=titanic_knn_variables[1][1]\n",
    "    clf = KNeighborsClassifier( n_neighbors=t[0],\n",
    "    weights=t[1],\n",
    "    leaf_size=t[2],\n",
    "    p=t[3])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_set.append(clf)\n",
    "    model_accuracies[f'knn_tupples[{i}]'] = {\n",
    "        'train_score': round(clf.score(X_train, y_train), 2),\n",
    "        'validate_score': round(clf.score(X_validate, y_validate), 2),\n",
    "        'diff': round(abs(clf.score(X_train, y_train)-clf.score(X_validate, y_validate)),2)}\n",
    "\n",
    "    dfdict.update((model_accuracies))   \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn_tupples[82]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[86]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[90]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[94]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[98]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[102]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[106]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[110]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[114]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_tupples[118]</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_score  validate_score  diff\n",
       "knn_tupples[82]          0.72            0.72   0.0\n",
       "knn_tupples[86]          0.72            0.72   0.0\n",
       "knn_tupples[90]          0.72            0.72   0.0\n",
       "knn_tupples[94]          0.72            0.72   0.0\n",
       "knn_tupples[98]          0.72            0.72   0.0\n",
       "knn_tupples[102]         0.72            0.72   0.0\n",
       "knn_tupples[106]         0.72            0.72   0.0\n",
       "knn_tupples[110]         0.72            0.72   0.0\n",
       "knn_tupples[114]         0.72            0.72   0.0\n",
       "knn_tupples[118]         0.72            0.72   0.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [display(i) for i in dflist]\n",
    "titatanic_knn=pd.DataFrame(dfdict)\n",
    "titatanic_knn=titatanic_knn.T\n",
    "titatanic_knn.nsmallest(columns='diff',keep='all',n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 'uniform', 30, 3],\n",
       " [20, 'uniform', 32, 3],\n",
       " [20, 'uniform', 34, 3],\n",
       " [20, 'uniform', 36, 3],\n",
       " [20, 'uniform', 38, 3],\n",
       " [20, 'uniform', 40, 3],\n",
       " [20, 'uniform', 42, 3],\n",
       " [20, 'uniform', 44, 3],\n",
       " [20, 'uniform', 46, 3],\n",
       " [20, 'uniform', 48, 3]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interesting_titatanic_knn=titatanic_knn.nsmallest(columns='diff',keep='all',n=1)\n",
    "interesting_titatanic_knn=interesting_titatanic_knn.T\n",
    "interestingtupples=list(interesting_titatanic_knn.columns)\n",
    "interestingtupples=[i.replace('knn_tupples','').replace('[','').replace(']','') for i in interestingtupples]\n",
    "[(knn_tupples[int(i)]) for i in interestingtupples]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises Logistic Regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n",
    "\n",
    "1. Create a model that includes age in addition to fare and pclass. Does this model  perform better than your baseline?\n",
    " \n",
    "1. Include sex in your model as well. Note that you'll need to encode or create a dummy 1. variable of this feature before including it in a model.\n",
    " \n",
    "1. Try out other combinations of features and models.\n",
    " \n",
    "1. Use you best 3 models to predict and evaluate on your validate sample.\n",
    " \n",
    "1. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l2', 1.0, {0: 1, 1: 99}, 'lbfgs', 300, 1.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACYAAAAQCAYAAAB6Hg0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABJ0AAASdAHeZh94AAAB/UlEQVR4nM3VTYiNcRQG8N+VspBSTFmQhRULZaZkJaTkIyKsKBaTna8Rk+I4VkbIZGNB5GOhNGOBFFEiWbAcoSxIPmpYILFwLd57dWPul4izeXvf85xznv95zvs/pXK57H+00Y2cmbkeZyqv3RFx4k/gM3MptmAGJuAVHuBIRNyDUQ2KTMExfGxEpl18ZvbhMjpxDf14iBW4m5nrqNOxzCzhFIYxgB1NirWEz8xJFd8bzIyItzW++biJ/ThXr2ObsQAb8akRqTbxUxUq3a8lBRFxCx/QwQhSZuZ0HEB/RNxuxqhN/FN8xezMnPhTnrkYhxv8JGVmjsZZPMfuFki1hY+Id5m5C0cwlJmXFPJPw3JcxyZ+7dhezMKGiPjcrNBv4EXEUaxSNKUbvViDFzhdlfgHscycrTj14eov28jaxdfE7cRFnFZ0aiy68AznM/OgCutaSZ5gTwvJ28LXxM1DHwYjYnuN62Fmrqzk68nM46VyuSwzx+N9i/n7sa8dfERsrRA7hB5sjohjIxAfwEqsrg7/F5ysk7hTMUd38Bj3fgNftTGVZ0ed2Or3r6VmuzIz9yG0sJKa4TNzLS4oLtiuiHhZ41uMK4pDT264K/+CXVTcUwvxKDMH8RrTsQwl9EbEcN1d+TcsIr5hCbZhSDFPPZiDq1gUEf3QVMp/Zd8BukvYb0BVLHQAAAAASUVORK5CYII=",
      "text/latex": [
       "\\begin{equation*}448\\end{equation*}"
      ],
      "text/plain": [
       "448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA0AAAAQCAYAAADNo/U5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABJ0AAASdAHeZh94AAABNklEQVR4nJXSP0vWYRTG8c/P/oBDBBI2NJRQmw0NBQn9GYwGJ8WWXoFjL0A6XDS09jbCxoiCJisKByHCQYlok1CycKgheFpu49fTM+RZLu5zn++5zoHTDQYDh42jo5JJruEeZjCBr/iAR1X17B8oyTIeYBdPsY1TuISb+BtKcqcBL7FQVftD/8egO9gpyRg+4jTOVdXO/+w0gyk8wV6SOUzjJ9aq6u0o6HLTL1jHxaHRVrFYVTtjvfxk0yWMYxYnmtsLXMfKsNORpl3r+L69N5LMYws3klztO+01/dQDQFX9aG5wpQ9tNv1mdBw0He9Dq/iFC0mOj4Cmm37+A1XVLh7jJO73q5Pcwm18x/Ouf7BJJvEG5/EKaziLeQxwt6pWuuErTzKB5VZ4Bvt4jYdV9Y7eGR0mfgNty2emUymaHAAAAABJRU5ErkJggg==",
      "text/latex": [
       "\\begin{equation*}6\\end{equation*}"
      ],
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logit_hyperpars_tupples(\n",
    "penalty=['l2'],\n",
    "C_list=np.arange(1,3,.5),\n",
    "class_weight_list=[{0:1, 1:99},'balanced'],\n",
    "\n",
    "solver_list=[ 'lbfgs','newton-cg'],\n",
    "max_iter_list=range(300,1000,100),\n",
    "intercept_scaling=np.arange(1,2,.25)\n",
    "):\n",
    "    '''\n",
    "    explore first to get decent ranges, this step is expensive\n",
    "\n",
    "    solver_list=[ 'newton-cg'] 'lbfgs','sag'],\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    n\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "   \n",
    "   \n",
    "    logit_tupple_array=[penalty,C_list,class_weight_list,solver_list,max_iter_list,intercept_scaling]\n",
    "\n",
    "    logit_tupples=list(reduce(product,logit_tupple_array))\n",
    "\n",
    "    logit_tupples=[\n",
    "        [\n",
    "        logit_tupples[i][0][0][0][0][0],\n",
    "        logit_tupples[i][0][0][0][0][1],\n",
    "        logit_tupples[i][0][0][0][1],\n",
    "        logit_tupples[i][0][0][1],\n",
    "        logit_tupples[i][0][1],\n",
    "        logit_tupples[i][1]] for i in range(0,len(logit_tupples))]\n",
    "  \n",
    "    \n",
    "\n",
    "    return logit_tupples\n",
    "\n",
    "logit_tupples=logit_hyperpars_tupples()\n",
    "display(\n",
    "logit_tupples[0],\n",
    "len(logit_tupples),\n",
    "len(logit_tupples[0])\n",
    "\n",
    "# logit_tupples[0][0][0][0][0][0],\n",
    "# logit_tupples[0][0][0][0][0][1],\n",
    "# logit_tupples[0][0][0][0][1],\n",
    "# logit_tupples[0][0][0][1],\n",
    "# logit_tupples[0][0][1],\n",
    "# logit_tupples[0][1]\n",
    "\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prepared Data</th>\n",
       "      <td>891</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>534</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validate</th>\n",
       "      <td>178</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>179</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Length  Width\n",
       "Prepared Data     891     11\n",
       "Train             534     11\n",
       "Validate          178     11\n",
       "Test              179     11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_titanic,validate_titanic,test_titanic =split_data(titanic,tostratify='survived_1')\n",
    "titanicDflist=[train_titanic,validate_titanic,test_titanic]\n",
    "titanic_knn_variables=[(i.drop(columns=['survived_1']),i.survived_1) for i in titanicDflist]\n",
    "\n",
    "\n",
    "\n",
    "# iteration:\n",
    "dfdict={}\n",
    "for i,t in enumerate(logit_tupples):\n",
    "    \n",
    "    model_set = []\n",
    "    model_accuracies = {}\n",
    "    X_train=titanic_knn_variables[0][0]## the X var for train\n",
    "    y_train=titanic_knn_variables[0][1]# the y var for train\n",
    "    X_validate=titanic_knn_variables[1][0]## the X var for val\n",
    "    y_validate=titanic_knn_variables[1][1]\n",
    "    \n",
    "    clf = LogisticRegression( \n",
    "        penalty=t[0],\n",
    "        C=t[1],\n",
    "        class_weight=t[2],\n",
    "        solver=t[3],\n",
    "        max_iter=t[4],\n",
    "        intercept_scaling=t[5]\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_set.append(clf)\n",
    "    model_accuracies[f'logit_tupples[{i}]'] = {\n",
    "        'train_score': round(clf.score(X_train, y_train), 2),\n",
    "        'validate_score': round(clf.score(X_validate, y_validate), 2),\n",
    "        'diff': round(abs(clf.score(X_train, y_train)-clf.score(X_validate, y_validate)),2)}\n",
    "\n",
    "    dfdict.update((model_accuracies))   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logit_tupples[0]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[1]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[2]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[3]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[4]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[387]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[388]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[389]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[390]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_tupples[391]</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train_score  validate_score  diff\n",
       "logit_tupples[0]           0.39            0.39   0.0\n",
       "logit_tupples[1]           0.39            0.39   0.0\n",
       "logit_tupples[2]           0.39            0.39   0.0\n",
       "logit_tupples[3]           0.39            0.39   0.0\n",
       "logit_tupples[4]           0.39            0.39   0.0\n",
       "...                         ...             ...   ...\n",
       "logit_tupples[387]         0.39            0.39   0.0\n",
       "logit_tupples[388]         0.39            0.39   0.0\n",
       "logit_tupples[389]         0.39            0.39   0.0\n",
       "logit_tupples[390]         0.39            0.39   0.0\n",
       "logit_tupples[391]         0.39            0.39   0.0\n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titatanic_logit=pd.DataFrame(dfdict)\n",
    "titatanic_logit=titatanic_logit.T\n",
    "titatanic_logit.nsmallest(columns='diff',keep='all',n=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_titatanic_logit=titatanic_logit.nsmallest(columns='diff',keep='all',n=1)\n",
    "\n",
    "interesting_titatanic_logit=interesting_titatanic_logit.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>300</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>300</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>300</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>300</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>400</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>800</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>900</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>900</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>900</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>l2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{0: 1, 1: 99}</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>900</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1              2          3    4     5\n",
       "0    l2  1.0  {0: 1, 1: 99}      lbfgs  300  1.00\n",
       "1    l2  1.0  {0: 1, 1: 99}      lbfgs  300  1.25\n",
       "2    l2  1.0  {0: 1, 1: 99}      lbfgs  300  1.50\n",
       "3    l2  1.0  {0: 1, 1: 99}      lbfgs  300  1.75\n",
       "4    l2  1.0  {0: 1, 1: 99}      lbfgs  400  1.00\n",
       "..   ..  ...            ...        ...  ...   ...\n",
       "219  l2  2.5  {0: 1, 1: 99}  newton-cg  800  1.75\n",
       "220  l2  2.5  {0: 1, 1: 99}  newton-cg  900  1.00\n",
       "221  l2  2.5  {0: 1, 1: 99}  newton-cg  900  1.25\n",
       "222  l2  2.5  {0: 1, 1: 99}  newton-cg  900  1.50\n",
       "223  l2  2.5  {0: 1, 1: 99}  newton-cg  900  1.75\n",
       "\n",
       "[224 rows x 6 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interestingtupples=list(interesting_titatanic_logit.columns)\n",
    "interestingtupples=[i.replace('logit_tupples','').replace('[','').replace(']','') for i in interestingtupples]\n",
    "\n",
    "logit_tupples_df=[logit_tupples[int(i)] for i in (interestingtupples)]\n",
    "\n",
    "logit_tupples_df=pd.DataFrame(logit_tupples_df)\n",
    "logit_tupples_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus1 \n",
    "How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "### Bonus2:\n",
    "How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "### Bonus3:\n",
    " scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "$$ C=.01,.1,1,10,100,1000 $$\n",
    "### Bonus Bonus:\n",
    " how does scaling the data interact with your choice of C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
